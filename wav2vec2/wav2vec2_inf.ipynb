{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from jiwer import wer\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRANSCRIPTIONS = \"./../eval/transcriptions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "pre_train_file = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(pre_train_file)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(pre_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr (/Users/lucasagrizzi/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc)\n",
      "Loading cached processed dataset at /Users/lucasagrizzi/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc/cache-9d56804bc919a18f.arrow\n"
     ]
    }
   ],
   "source": [
    "# define function to read in sound file\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "    \n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Audio\n",
    "# import numpy\n",
    "\n",
    "# wave_audio = numpy.sin(numpy.linspace(0, 3000, 20000))\n",
    "# Audio(wave_audio, rate=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize constants\n",
    "transcriptions = []\n",
    "error = []\n",
    "inference_time = []\n",
    "\n",
    "len_ds = len(ds[\"text\"])\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len_ds//BATCH_SIZE):\n",
    "\n",
    "    # import audio\n",
    "    audio = ds[\"speech\"][i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "\n",
    "    # count time of inference\n",
    "    start = time.time()\n",
    "    \n",
    "    # tokenize\n",
    "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "\n",
    "    # retrieve logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # take argmax and decode\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    # store time of inference\n",
    "    inference_time.append(time.time() - start)\n",
    "\n",
    "    # store transcription\n",
    "    transcriptions.append(transcription)\n",
    "\n",
    "transcriptions = list(np.array(transcriptions).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcriptions = pd.DataFrame(ds[\"text\"][:len_ds], columns=['ground_truth'])\n",
    "df_transcriptions[pre_train_file] = transcriptions\n",
    "df_transcriptions[pre_train_file + \"_inf_time\"] = inference_time\n",
    "\n",
    "\n",
    "df_transcriptions[pre_train_file] = df_transcriptions[pre_train_file].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>facebook/wav2vec2-large-960h-lv60-self</th>\n",
       "      <th>facebook/wav2vec2-large-960h-lv60-self_inf_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A MAN SAID TO THE UNIVERSE SIR I EXIST</td>\n",
       "      <td>A MAN SAID TO THE UNIVERSE SIR I EXIST</td>\n",
       "      <td>5.948975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWEAT COVERED BRION'S BODY TRICKLING INTO THE ...</td>\n",
       "      <td>SWEAT COVERED BRION'S BODY TRICKLING INTO THE ...</td>\n",
       "      <td>7.317595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE CUT ON HIS CHEST STILL DRIPPING BLOOD THE ...</td>\n",
       "      <td>THE CUT ON HIS CHEST STILL DRIPPING BLOOD THE ...</td>\n",
       "      <td>14.338364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIS INSTANT OF PANIC WAS FOLLOWED BY A SMALL S...</td>\n",
       "      <td>HIS INSTANT PANIC WAS FOLLOWED BY A SMALL SHAR...</td>\n",
       "      <td>6.099911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ONE MINUTE A VOICE SAID AND THE TIME BUZZER SO...</td>\n",
       "      <td>ONE MINUTE A VOICE SAID AND THE TIME BUZZER SO...</td>\n",
       "      <td>5.535601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>I DON'T BELIEVE ANN KNEW ANY MAGIC OR SHE'D HA...</td>\n",
       "      <td>I DON'T BELIEVE ANNE KNEW ANY MAGIC OR SHE'D H...</td>\n",
       "      <td>12.336592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>I DO NOT KNOW CONFESSED SHAGGY</td>\n",
       "      <td>I DO NOT KNOW CONFESSED SHAGGY</td>\n",
       "      <td>19.080031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>TRUE AGREED KALIKO</td>\n",
       "      <td>TRUE A GREEN CALICO</td>\n",
       "      <td>15.415310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>KALIKO WENT TO THE BIG GONG AND POUNDED ON IT ...</td>\n",
       "      <td>CALICO WENT TO THE BIG GONG AND POUNDED ON IT ...</td>\n",
       "      <td>18.959109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>HAVING RETURNED TO THE ROYAL CAVERN KALIKO FIR...</td>\n",
       "      <td>HAVING RETURNED TO THE ROYAL CAVERN CALICO FIR...</td>\n",
       "      <td>33.335845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ground_truth  \\\n",
       "0              A MAN SAID TO THE UNIVERSE SIR I EXIST   \n",
       "1   SWEAT COVERED BRION'S BODY TRICKLING INTO THE ...   \n",
       "2   THE CUT ON HIS CHEST STILL DRIPPING BLOOD THE ...   \n",
       "3   HIS INSTANT OF PANIC WAS FOLLOWED BY A SMALL S...   \n",
       "4   ONE MINUTE A VOICE SAID AND THE TIME BUZZER SO...   \n",
       "..                                                ...   \n",
       "68  I DON'T BELIEVE ANN KNEW ANY MAGIC OR SHE'D HA...   \n",
       "69                     I DO NOT KNOW CONFESSED SHAGGY   \n",
       "70                                 TRUE AGREED KALIKO   \n",
       "71  KALIKO WENT TO THE BIG GONG AND POUNDED ON IT ...   \n",
       "72  HAVING RETURNED TO THE ROYAL CAVERN KALIKO FIR...   \n",
       "\n",
       "               facebook/wav2vec2-large-960h-lv60-self  \\\n",
       "0              A MAN SAID TO THE UNIVERSE SIR I EXIST   \n",
       "1   SWEAT COVERED BRION'S BODY TRICKLING INTO THE ...   \n",
       "2   THE CUT ON HIS CHEST STILL DRIPPING BLOOD THE ...   \n",
       "3   HIS INSTANT PANIC WAS FOLLOWED BY A SMALL SHAR...   \n",
       "4   ONE MINUTE A VOICE SAID AND THE TIME BUZZER SO...   \n",
       "..                                                ...   \n",
       "68  I DON'T BELIEVE ANNE KNEW ANY MAGIC OR SHE'D H...   \n",
       "69                     I DO NOT KNOW CONFESSED SHAGGY   \n",
       "70                                TRUE A GREEN CALICO   \n",
       "71  CALICO WENT TO THE BIG GONG AND POUNDED ON IT ...   \n",
       "72  HAVING RETURNED TO THE ROYAL CAVERN CALICO FIR...   \n",
       "\n",
       "    facebook/wav2vec2-large-960h-lv60-self_inf_time  \n",
       "0                                          5.948975  \n",
       "1                                          7.317595  \n",
       "2                                         14.338364  \n",
       "3                                          6.099911  \n",
       "4                                          5.535601  \n",
       "..                                              ...  \n",
       "68                                        12.336592  \n",
       "69                                        19.080031  \n",
       "70                                        15.415310  \n",
       "71                                        18.959109  \n",
       "72                                        33.335845  \n",
       "\n",
       "[73 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcriptions.to_csv(PATH_TRANSCRIPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2f835dcc56ed6808b054c78edb3a7e1664abbb81c08b1e4b7105b37ec023d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('wav2vec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
